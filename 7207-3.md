---
      
title: 3
      
created: 2025-04-30
      
source: Cherry Studio
      
tags: 
      
---

### 径向基函数（RBF）神经网络学习文档

#### 第一部分：RBF神经网络概述

##### 1.1 生物学背景与灵感
在生物体的神经系统中，某些神经元的响应具有“局部性”，即对输入空间的特定区域有较高的敏感性。例如，视觉皮层的方向敏感细胞对视网膜特定区域的刺激表现出强烈的响应。受此启发，径向基函数（RBF）神经网络被设计出来，模拟这种局部调谐的特性。

##### 1.2 RBF神经网络简介
RBF神经网络是一种前馈神经网络，其特点在于隐藏层的设计和训练方法。隐藏层中的神经元响应是局部的，随着输入到神经元接收场中心的距离增加，响应值会逐渐衰减。其架构通常包括输入层、隐藏层和输出层。

---

#### 第二部分：RBF神经网络架构与特性

##### 2.1 网络结构
RBF神经网络的典型架构如下：
- **输入层**：不进行任何计算，仅将输入数据传递到隐藏层。
- **隐藏层**：隐藏层神经元具有局部调谐特性，权重通常固定为1。隐藏层神经元的操作可以表示为：
  $$
  d_i = ||\mathbf{x} - \mathbf{c}_i||
  $$
  $$
  o_i = g(d_i) = g(|\mathbf{x} - \mathbf{c}_i|)
  $$
  其中，$\mathbf{c}_i$ 是神经元 $i$ 的中心向量（接收场中心），$g(\cdot)$ 是径向基函数。

- **常用径向基函数**：
  1. **高斯函数**：
     $$
     g(d_i) = \exp\left(-\frac{d_i^2}{2\sigma^2}\right)
     $$
     其中 $\sigma$ 是基函数的宽度，决定接收场的大小。
  2. **反多元二次函数**：
     $$
     g(d_i) = \frac{1}{\sqrt{d_i^2 + \sigma^2}}
     $$
     其响应随 $\sigma$ 的变化而调整。

- **输出层**：输出层为线性组合器，网络输出为隐藏层输出的加权和：
  $$
  f(\mathbf{x}) = \sum_{j=1}^m w_j o_j(\mathbf{x}) + w_0
  $$
  其中，$m$ 是隐藏层神经元数量，$w_j$ 是从隐藏层到输出层的权重，$w_0$ 是偏置项。

##### 2.2 网络参数
RBF神经网络的响应由以下参数决定：
- 中心向量 $\mathbf{c}_j$，$j=1,2,\dots,m$
- 权重 $w_j$，$j=0,1,2,\dots,m$
- 基函数宽度 $\sigma$

需要注意的是，网络输出与隐藏层输出呈线性关系，但对 $\sigma$ 和 $\mathbf{c}_j$ 呈非线性关系。

##### 2.3 映射过程
RBF神经网络的映射过程可以分为两步：
1. **非线性映射**：从输入空间到隐藏空间，通过径向基函数实现。
2. **线性映射**：从隐藏空间到输出空间，通过权重和偏置实现线性组合。

这种两步映射在非线性分类问题中特别有效，例如将输入空间中非线性可分的数据映射到隐藏空间中，使其线性可分。

---

#### 第三部分：RBF神经网络训练方法

##### 3.1 中心向量确定方法
中心向量 $\mathbf{c}_j$ 的选择直接影响隐藏层神经元的局部响应特性。以下是几种常见方法：

1. **从训练样本中随机选择**：
   - 方法：从训练数据中随机选取中心向量，或在数据区域内随机生成。
   - 优点：实现简单。
   - 缺点：若神经元数量较少，可能无法有效覆盖输入空间。
   - 宽度设置建议：
     $$
     \sigma = \frac{d_{\text{max}}}{\sqrt{2m}}
     $$
     其中 $d_{\text{max}}$ 是所选中心向量之间的最大距离，$m$ 是隐藏层神经元数量，确保基函数不会过于尖锐或平坦。

2. **使用训练样本原型**：
   - 方法：选择代表性的训练样本作为中心向量，确保中心位于数据密集区域。
   - 实现：可通过自组织映射（SOM）或K均值聚类等算法确定原型。
   - 优点：比随机选择更能代表数据分布。

3. **将中心向量选择视为特征选择问题**：
   - 方法：将训练样本映射到隐藏空间，视为特征空间，从中选择最具区分性的特征（对应中心向量）。
   - 过程：
     1. 将所有训练样本作为中心向量，输入 $\mathbf{x}(k)$ 从 $n$ 维输入空间映射到 $N$ 维隐藏空间：
        $$
        \mathbf{o}(k) = [o_1(k), o_2(k), \dots, o_N(k)]^T
        $$
        其中 $o_j(k) = \exp\left(-\frac{||\mathbf{x}(k) - \mathbf{c}_j||^2}{2\sigma^2}\right)$。
     2. 使用可分性度量选择 $m$ 个特征（即 $m$ 个中心向量）。
   - 常用可分性度量：
     1. **马哈拉诺比斯距离**：
        $$
        J = (\mathbf{m}_1 - \mathbf{m}_2)^T \mathbf{C}^{-1} (\mathbf{m}_1 - \mathbf{m}_2)
        $$
        其中 $\mathbf{m}_1, \mathbf{m}_2$ 是两类的均值向量，$\mathbf{C}$ 是协方差矩阵。
     2. **散度矩阵度量**：
        $$
        J = \frac{\text{Tr}(\mathbf{S}_B)}{\text{Tr}(\mathbf{S}_W)} \quad \text{或} \quad J = \text{Tr}(\mathbf{S}_W^{-1} \mathbf{S}_B)
        $$
        其中 $\mathbf{S}_B$ 是类间散度矩阵，$\mathbf{S}_W$ 是类内散度矩阵。
   - 特征选择算法：
     - **自底向上（前向选择）**：从空集开始，逐步添加对可分性贡献最大的特征。
     - **自顶向下（后向消除）**：从全集开始，逐步移除对可分性贡献最小的特征。

##### 3.2 权重估计
由于输出层是线性组合，权重估计可通过线性方法完成，常用方法包括线性判别分析、线性支持向量机和线性最小二乘估计。

- **线性最小二乘估计**：
  给定 $N$ 个训练样本 $\{\mathbf{x}(k), d(k)\}$，网络输出为：
  $$
  f[\mathbf{x}(k)] = \sum_{j=1}^m w_j o_j(k) + w_0
  $$
  矩阵形式为：
  $$
  \mathbf{f} = \mathbf{\Phi} \mathbf{w}
  $$
  其中 $\mathbf{f}$ 是网络输出向量，$\mathbf{\Phi}$ 是隐藏层输出矩阵，$\mathbf{w}$ 是权重向量。
  损失函数为：
  $$
  J = \sum_{k=1}^N \{f[\mathbf{x}(k)] - d(k)\}^2 = (\mathbf{f} - \mathbf{d})^T (\mathbf{f} - \mathbf{d})
  $$
  通过求解 $\frac{\partial J}{\partial \mathbf{w}} = 0$，得到权重估计：
  $$
  \mathbf{w} = (\mathbf{\Phi}^T \mathbf{\Phi})^{-1} \mathbf{\Phi}^T \mathbf{d}
  $$

##### 3.3 基于非线性优化的中心向量与权重估计
中心向量、权重和宽度可以通过单一的非线性优化过程（如梯度下降法）同时学习。损失函数定义为：
$$
E = \frac{1}{2} \sum_{k=1}^N e_k^2, \quad e_k = f[\mathbf{x}(k)] - d(k)
$$
通过梯度下降更新参数：
- 权重更新：
  $$
  \frac{\partial E(n)}{\partial w_j(n)} = \sum_{k=1}^N e_k(n) \exp\left(-\frac{||\mathbf{x}(k) - \mathbf{c}_j(n)||^2}{2\sigma^2(n)}\right)
  $$
  $$
  w_j(n+1) = w_j(n) - \eta_1 \frac{\partial E(n)}{\partial w_j(n)}
  $$
- 中心向量更新：
  $$
  \frac{\partial E(n)}{\partial \mathbf{c}_j(n)} = w_j(n) \sum_{k=1}^N e_k(n) \exp\left(-\frac{||\mathbf{x}(k) - \mathbf{c}_j(n)||^2}{2\sigma^2(n)}\right) \frac{\mathbf{x}(k) - \mathbf{c}_j(n)}{\sigma^2(n)}
  $$
  $$
  \mathbf{c}_j(n+1) = \mathbf{c}_j(n) - \eta_2 \frac{\partial E(n)}{\partial \mathbf{c}_j(n)}
  $$
- 宽度更新：
  $$
  \frac{\partial E(n)}{\partial \sigma(n)} = \sum_{k=1}^N e_k(n) \sum_{j=1}^m w_j \exp\left(-\frac{||\mathbf{x}(k) - \mathbf{c}_j(n)||^2}{2\sigma^2(n)}\right) \frac{||\mathbf{x}(k) - \mathbf{c}_j(n)||^2}{\sigma^3(n)}
  $$
  $$
  \sigma(n+1) = \sigma(n) - \eta_3 \frac{\partial E(n)}{\partial \sigma(n)}
  $$
  迭代直至参数变化趋于稳定。

---

#### 第四部分：例题与解答

##### 例题：异或（XOR）问题
**问题描述**：考虑异或逻辑运算，输入和输出如下：
- 输入 [1, 1]^T，输出 0
- 输入 [0, 1]^T，输出 1
- 输入 [0, 0]^T，输出 0
- 输入 [1, 0]^T，输出 1

假设使用两个隐藏层神经元，中心向量设为 $\mathbf{c}_1 = [1, 1]^T$，$\mathbf{c}_2 = [0, 0]^T$，高斯基函数宽度 $\sigma = 0.707$。

**求解步骤**：
1. 计算每个输入在隐藏层的输出：
   对于输入 $\mathbf{x}(k)$，隐藏层输出为：
   $$
   o_j(k) = \exp\left(-\frac{||\mathbf{x}(k) - \mathbf{c}_j||^2}{2\sigma^2}\right)
   $$
   经计算，隐藏层输出矩阵 $\mathbf{\Phi}$ 为：
   $$
   \mathbf{\Phi} = \begin{bmatrix}
   1 & 1 & 0.1353 \\
   1 & 0.3678 & 0.3678 \\
   1 & 1 & 0.1353 \\
   1 & 0.3678 & 0.3678
   \end{bmatrix}
   $$

2. 目标输出向量 $\mathbf{d} = [0, 1, 0, 1]^T$。

3. 使用线性最小二乘估计权重：
   $$
   \mathbf{w} = (\mathbf{\Phi}^T \mathbf{\Phi})^{-1} \mathbf{\Phi}^T \mathbf{d}
   $$
   解得：
   $$
   \mathbf{w} = [2.8404, -2.5018, -2.5018]^T
   $$
   即 $w_0 = 2.8404$，$w_1 = -2.5018$，$w_2 = -2.5018$。

4. 验证网络性能：
   - 输入 [1, 1]^T，$f(\mathbf{x}) \approx 0.000106$（接近0）
   - 输入 [0, 1]^T，$f(\mathbf{x}) \approx 1.0001$（接近1）
   - 输入 [0, 0]^T，$f(\mathbf{x}) \approx 0.000106$（接近0）
   - 输入 [1, 0]^T，$f(\mathbf{x}) \approx 1.0001$（接近1）

**结论**：RBF神经网络仅用两个隐藏层神经元即可很好地近似XOR逻辑运算。

---

#### 第五部分：应用案例

##### 案例：保险客户分类
**背景**：一家保险公司希望推广房车保险计划，需从4000名测试客户中选出800名最可能感兴趣的客户。

**数据**：
- 训练数据：5822名客户，85个属性（包括社会人口统计数据和是否拥有房车保险标签），其中348人拥有房车保险（类1），5474人未拥有（类2），数据不平衡。
- 测试数据：4000名客户，标签未知。

**解决方案**：
1. **数据预处理**：
   - 解决不平衡问题：从5474名类2客户中通过SOM神经网络选择500名代表性样本，构成新训练集（348+500=848）。
   - 特征选择：从85个属性中剔除无关、冗余属性，保留12个有用属性。

2. **模型训练**：
   - 隐藏层神经元数量：通过前向选择方法，基于可分性度量选择7个神经元。
   - 中心向量：从848个训练样本中选择7个中心向量。
   - 权重估计：使用线性最小二乘法最小化损失函数：
     $$
     J = \sum_{k=1}^{848} \{f[\mathbf{x}(k)] - d(k)\}^2
     $$
     其中 $d(k)=1$（类1）或 $-1$（类2）。

3. **预测与评估**：
   - 对4000名测试客户预测感兴趣概率，选出800名可能性最高的客户。
   - 结果：实际有238名客户拥有房车保险，RBF模型正确识别105名，随机选择仅识别约46名，显示出机器学习的显著优势。

---

#### 第六部分：总结
RBF神经网络通过局部调谐的隐藏层神经元实现非线性映射，结合线性输出层解决复杂分类和回归问题。其训练过程包括中心向量选择、权重估计及非线性优化等步骤，广泛应用于模式分类和预测任务中。通过上述理论、例题和案例的学习，读者应能掌握RBF神经网络的基本原理、训练方法及应用场景。